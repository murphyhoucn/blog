

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202505301726222.png">
  <link rel="icon" href="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202505301728148.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Murphy">
  <meta name="keywords" content="Murphy,CosmicDusty,murphy,cosmicdusty,cn">
  
    <meta name="description" content="试玩一下JetsonTX2!">
<meta property="og:type" content="article">
<meta property="og:title" content="JetsonTX2">
<meta property="og:url" content="https://blog.cosmicdusty.cc/post/CV/InitJetsonTX2/index.html">
<meta property="og:site_name" content="CosmicDusty-Blog">
<meta property="og:description" content="试玩一下JetsonTX2!">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202505311244390.webp">
<meta property="article:published_time" content="2024-04-23T04:23:15.000Z">
<meta property="article:modified_time" content="2025-06-06T08:06:10.097Z">
<meta property="article:author" content="Murphy">
<meta property="article:tag" content="OpenMMLab">
<meta property="article:tag" content="EdgeComputing">
<meta property="article:tag" content="Arm">
<meta property="article:tag" content="MMDeploy">
<meta property="article:tag" content="MMCV">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202505311244390.webp">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>JetsonTX2 - CosmicDusty-Blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"blog.cosmicdusty.cc","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":"16d93d5abbd7ea15ec53daed5459ebf7","google":null,"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":"JijHNKemeVNog4wF7g9I5TR3","app_key":"FvsKdxHOP2aG5rHrHby5aV0b","server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null},"gtag":null,"woyaola":null,"cnzz":null},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  
    <!-- Baidu Analytics -->
    <script async>
      if (!Fluid.ctx.dnt) {
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?16d93d5abbd7ea15ec53daed5459ebf7";
          var s = document.getElementsByTagName("script")[0];
          s.parentNode.insertBefore(hm, s);
        })();
      }
    </script>
  

  

  

  

  
    
  



  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>CosmicDusty</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/" target="_self">
                <i class="iconfont icon-link-fill"></i>
                <span>友链</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202505311244390.webp') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="JetsonTX2"></span>
          
        </div>

        
          
  <div class="mt-3">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-author" aria-hidden="true"></i>
        Murphy
      </span>
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-04-23 12:23" pubdate>
          2024年4月23日 中午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          4.5k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          38 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">JetsonTX2</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="TX2-刷机"><a href="#TX2-刷机" class="headerlink" title="TX2 刷机"></a>TX2 刷机</h1><ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/580836187">TX2刷机教程（主机为Ubuntu版本） - 知乎</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/masbay/p/10718514.html">ubuntu双系统启动时卡死解决办法 - 不妨不妨，来日方长 - 博客园</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/496824140">Nvidia Jetson TX2 详细刷机教程及踩坑记录（Jetpack4.5.1，python3.6，torch1.6，torchvision0.7） - 知乎</a></li>
</ul>
<h1 id="TX2基本信息"><a href="#TX2基本信息" class="headerlink" title="TX2基本信息"></a>TX2基本信息</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看Jetson TX2 L4T版本</span><br>(mmdeploy36) npu@ubuntu:~$ <span class="hljs-built_in">head</span> -n 1 /etc/nv_tegra_release<br><span class="hljs-comment"># R32 (release), REVISION: 7.4, GCID: 33514132, BOARD: t186ref, EABI: aarch64, DATE: Fri Jun  9 04:18:38 UTC 2023</span><br><br><span class="hljs-comment"># 查看nvidia-jetpack版本</span><br>(mmdeploy36) npu@ubuntu:~$ <span class="hljs-built_in">sudo</span> apt-cache show nvidia-jetpack<br>[<span class="hljs-built_in">sudo</span>] password <span class="hljs-keyword">for</span> npu:<br>Package: nvidia-jetpack<br>Version: 4.6.6-b24<br>Architecture: arm64<br>Maintainer: NVIDIA Corporation<br>Installed-Size: 194<br>Depends: nvidia-l4t-jetson-multimedia-api (&gt;&gt; 32.7-0), nvidia-l4t-jetson-multimedia-api (&lt;&lt; <span class="hljs-string">32.8-0), nvidia-cuda (= 4.6.6-b24), nvidia-tensorrt (= 4.6.6-b24), nvidia-nsight-sys (= 4.6.6-b24), nvidia-cudnn8 (= 4.6.6-b24), nvidia-opencv (= 4.6.6-b24), nvidia-container (= 4.6.6-b24), nvidia-visionworks (= 4.6.6-b24), nvidia-vpi (= 4.6.6-b24)</span><br><span class="hljs-string">Homepage: http://developer.nvidia.com/jetson</span><br><span class="hljs-string">Priority: standard</span><br><span class="hljs-string">Section: metapackages</span><br><span class="hljs-string">Filename: pool/main/n/nvidia-jetpack/nvidia-jetpack_4.6.6-b24_arm64.deb</span><br><span class="hljs-string">Size: 29376</span><br><span class="hljs-string">SHA256: 1292cfb107353f83eb18c96e6c3fce58e07dcf5f517db6039a5469c5bb30d743</span><br><span class="hljs-string">SHA1: 62d3915566d21dad24dcc0b5147e81971e776f7f</span><br><span class="hljs-string">MD5sum: d887402512142323c5ff2811e40c2ac6</span><br><span class="hljs-string">Description: NVIDIA Jetpack Meta Package</span><br><span class="hljs-string">Description-md5: ad1462289bdbc54909ae109d1d32c0a8</span><br><span class="hljs-string"></span><br><span class="hljs-string">Package: nvidia-jetpack</span><br><span class="hljs-string">Version: 4.6.5-b29</span><br><span class="hljs-string">Architecture: arm64</span><br><span class="hljs-string">Maintainer: NVIDIA Corporation</span><br><span class="hljs-string">Installed-Size: 194</span><br><span class="hljs-string">Depends: nvidia-l4t-jetson-multimedia-api (&gt;&gt; 32</span>.7-0), nvidia-l4t-jetson-multimedia-api (&lt;&lt; <span class="hljs-string">32.8-0), nvidia-cuda (= 4.6.5-b29), nvidia-tensorrt (= 4.6.5-b29), nvidia-nsight-sys (= 4.6.5-b29), nvidia-cudnn8 (= 4.6.5-b29), nvidia-opencv (= 4.6.5-b29), nvidia-container (= 4.6.5-b29), nvidia-visionworks (= 4.6.5-b29), nvidia-vpi (= 4.6.5-b29)</span><br><span class="hljs-string">Homepage: http://developer.nvidia.com/jetson</span><br><span class="hljs-string">Priority: standard</span><br><span class="hljs-string">Section: metapackages</span><br><span class="hljs-string">Filename: pool/main/n/nvidia-jetpack/nvidia-jetpack_4.6.5-b29_arm64.deb</span><br><span class="hljs-string">Size: 29382</span><br><span class="hljs-string">SHA256: 3347532325b9e216c38274bbbc076d6f368fdd0423bad4de8860a7c2ac7da7c2</span><br><span class="hljs-string">SHA1: ad441acc5493fbcbae4f3243193bf6e47088da54</span><br><span class="hljs-string">MD5sum: 1d79a14bc5b01c0254b0fc45ec29e5db</span><br><span class="hljs-string">Description: NVIDIA Jetpack Meta Package</span><br><span class="hljs-string">Description-md5: ad1462289bdbc54909ae109d1d32c0a8</span><br><span class="hljs-string"></span><br><span class="hljs-string">Package: nvidia-jetpack</span><br><span class="hljs-string">Version: 4.6.4-b39</span><br><span class="hljs-string">Architecture: arm64</span><br><span class="hljs-string">Maintainer: NVIDIA Corporation</span><br><span class="hljs-string">Installed-Size: 194</span><br><span class="hljs-string">Depends: nvidia-l4t-jetson-multimedia-api (&gt;&gt; 32</span>.7-0), nvidia-l4t-jetson-multimedia-api (&lt;&lt; <span class="hljs-string">32.8-0), nvidia-cuda (= 4.6.4-b39), nvidia-tensorrt (= 4.6.4-b39), nvidia-nsight-sys (= 4.6.4-b39), nvidia-cudnn8 (= 4.6.4-b39), nvidia-opencv (= 4.6.4-b39), nvidia-container (= 4.6.4-b39), nvidia-visionworks (= 4.6.4-b39), nvidia-vpi (= 4.6.4-b39)</span><br><span class="hljs-string">Homepage: http://developer.nvidia.com/jetson</span><br><span class="hljs-string">Priority: standard</span><br><span class="hljs-string">Section: metapackages</span><br><span class="hljs-string">Filename: pool/main/n/nvidia-jetpack/nvidia-jetpack_4.6.4-b39_arm64.deb</span><br><span class="hljs-string">Size: 29372</span><br><span class="hljs-string">SHA256: 9b2c9b8ba59f245b53fa9c2d4ddd05017db5c1df9e26a7e01ce5fe25928e2cdd</span><br><span class="hljs-string">SHA1: b2e3184f05852db99888bed90114642f0b506618</span><br><span class="hljs-string">MD5sum: 1a1f0c74067ea5a122adb69d24965583</span><br><span class="hljs-string">Description: NVIDIA Jetpack Meta Package</span><br><span class="hljs-string">Description-md5: ad1462289bdbc54909ae109d1d32c0a8</span><br><span class="hljs-string"></span><br><span class="hljs-string">Package: nvidia-jetpack</span><br><span class="hljs-string">Version: 4.6.3-b17</span><br><span class="hljs-string">Architecture: arm64</span><br><span class="hljs-string">Maintainer: NVIDIA Corporation</span><br><span class="hljs-string">Installed-Size: 194</span><br><span class="hljs-string">Depends: nvidia-l4t-jetson-multimedia-api (&gt;&gt; 32</span>.7-0), nvidia-l4t-jetson-multimedia-api (&lt;&lt; <span class="hljs-string">32.8-0), nvidia-cuda (= 4.6.3-b17), nvidia-tensorrt (= 4.6.3-b17), nvidia-nsight-sys (= 4.6.3-b17), nvidia-cudnn8 (= 4.6.3-b17), nvidia-opencv (= 4.6.3-b17), nvidia-container (= 4.6.3-b17), nvidia-vpi (= 4.6.3-b17)</span><br><span class="hljs-string">Homepage: http://developer.nvidia.com/jetson</span><br><span class="hljs-string">Priority: standard</span><br><span class="hljs-string">Section: metapackages</span><br><span class="hljs-string">Filename: pool/main/n/nvidia-jetpack/nvidia-jetpack_4.6.3-b17_arm64.deb</span><br><span class="hljs-string">Size: 29358</span><br><span class="hljs-string">SHA256: 7ca14bc60ce91e17c0ee5d30b327d103c4d2d4cf9d34437c3865d7e9a5c5283a</span><br><span class="hljs-string">SHA1: bdfde20b6e453fec1f780d147ef6c29e0eafa723</span><br><span class="hljs-string">MD5sum: 115c7c6f0e1e971e6cce5997929f21c8</span><br><span class="hljs-string">Description: NVIDIA Jetpack Meta Package</span><br><span class="hljs-string">Description-md5: ad1462289bdbc54909ae109d1d32c0a8</span><br><span class="hljs-string"></span><br><span class="hljs-string">Package: nvidia-jetpack</span><br><span class="hljs-string">Version: 4.6.2-b5</span><br><span class="hljs-string">Architecture: arm64</span><br><span class="hljs-string">Maintainer: NVIDIA Corporation</span><br><span class="hljs-string">Installed-Size: 194</span><br><span class="hljs-string">Depends: nvidia-cuda (= 4.6.2-b5), nvidia-opencv (= 4.6.2-b5), nvidia-cudnn8 (= 4.6.2-b5), nvidia-tensorrt (= 4.6.2-b5), nvidia-visionworks (= 4.6.2-b5), nvidia-container (= 4.6.2-b5), nvidia-vpi (= 4.6.2-b5), nvidia-l4t-jetson-multimedia-api (&gt;&gt; 32</span>.7-0), nvidia-l4t-jetson-multimedia-api (&lt;&lt; <span class="hljs-string">32.8-0)</span><br><span class="hljs-string">Homepage: http://developer.nvidia.com/jetson</span><br><span class="hljs-string">Priority: standard</span><br><span class="hljs-string">Section: metapackages</span><br><span class="hljs-string">Filename: pool/main/n/nvidia-jetpack/nvidia-jetpack_4.6.2-b5_arm64.deb</span><br><span class="hljs-string">Size: 29356</span><br><span class="hljs-string">SHA256: 6e3cf64d4fb46224c213ebd0cadae22d14c25dbe6dc3628d6440beeab33fed8d</span><br><span class="hljs-string">SHA1: 35cd143b91a323dae4ecfd2d2f907a0efd2fb9aa</span><br><span class="hljs-string">MD5sum: f0c9e65929dd73796967822c2fd99f3d</span><br><span class="hljs-string">Description: NVIDIA Jetpack Meta Package</span><br><span class="hljs-string">Description-md5: ad1462289bdbc54909ae109d1d32c0a8</span><br><span class="hljs-string"></span><br><span class="hljs-string">Package: nvidia-jetpack</span><br><span class="hljs-string">Version: 4.6.1-b110</span><br><span class="hljs-string">Architecture: arm64</span><br><span class="hljs-string">Maintainer: NVIDIA Corporation</span><br><span class="hljs-string">Installed-Size: 194</span><br><span class="hljs-string">Depends: nvidia-cuda (= 4.6.1-b110), nvidia-opencv (= 4.6.1-b110), nvidia-cudnn8 (= 4.6.1-b110), nvidia-tensorrt (= 4.6.1-b110), nvidia-visionworks (= 4.6.1-b110), nvidia-container (= 4.6.1-b110), nvidia-vpi (= 4.6.1-b110), nvidia-l4t-jetson-multimedia-api (&gt;&gt; 32</span>.7-0), nvidia-l4t-jetson-multimedia-api (&lt;&lt; <span class="hljs-string">32.8-0)</span><br><span class="hljs-string">Homepage: http://developer.nvidia.com/jetson</span><br><span class="hljs-string">Priority: standard</span><br><span class="hljs-string">Section: metapackages</span><br><span class="hljs-string">Filename: pool/main/n/nvidia-jetpack/nvidia-jetpack_4.6.1-b110_arm64.deb</span><br><span class="hljs-string">Size: 29370</span><br><span class="hljs-string">SHA256: 0663eb94d983e9eb86afdce4a3c73cf2ce040055862b4e711c28cb682b5fcb6e</span><br><span class="hljs-string">SHA1: 9011104940e9095743f5e76e0f7634dd04dedb93</span><br><span class="hljs-string">MD5sum: 8f6d3d3acb592faae54deed432f34b20</span><br><span class="hljs-string">Description: NVIDIA Jetpack Meta Package</span><br><span class="hljs-string">Description-md5: ad1462289bdbc54909ae109d1d32c0a8</span><br><span class="hljs-string"></span><br><span class="hljs-string"># TensorRT</span><br><span class="hljs-string">(mmdeploy36) npu@ubuntu:~$ dpkg -l | grep TensorRT</span><br><span class="hljs-string">ii  graphsurgeon-tf                                       8.2.1-1+cuda10.2                           arm64        GraphSurgeon for TensorRT package</span><br><span class="hljs-string">ii  libnvinfer-bin                                        8.2.1-1+cuda10.2                           arm64        TensorRT binaries</span><br><span class="hljs-string">ii  libnvinfer-dev                                        8.2.1-1+cuda10.2                           arm64        TensorRT development libraries and headers</span><br><span class="hljs-string">ii  libnvinfer-doc                                        8.2.1-1+cuda10.2                           all          TensorRT documentation</span><br><span class="hljs-string">ii  libnvinfer-plugin-dev                                 8.2.1-1+cuda10.2                           arm64        TensorRT plugin libraries</span><br><span class="hljs-string">ii  libnvinfer-plugin8                                    8.2.1-1+cuda10.2                           arm64        TensorRT plugin libraries</span><br><span class="hljs-string">ii  libnvinfer-samples                                    8.2.1-1+cuda10.2                           all          TensorRT samples</span><br><span class="hljs-string">ii  libnvinfer8                                           8.2.1-1+cuda10.2                           arm64        TensorRT runtime libraries</span><br><span class="hljs-string">ii  libnvonnxparsers-dev                                  8.2.1-1+cuda10.2                           arm64        TensorRT ONNX libraries</span><br><span class="hljs-string">ii  libnvonnxparsers8                                     8.2.1-1+cuda10.2                           arm64        TensorRT ONNX libraries</span><br><span class="hljs-string">ii  libnvparsers-dev                                      8.2.1-1+cuda10.2                           arm64        TensorRT parsers libraries</span><br><span class="hljs-string">ii  libnvparsers8                                         8.2.1-1+cuda10.2                           arm64        TensorRT parsers libraries</span><br><span class="hljs-string">ii  nvidia-container-csv-tensorrt                         8.2                                        arm64        Jetpack TensorRT CSV file</span><br><span class="hljs-string">ii  python3-libnvinfer                                    8.2.1-1+cuda10.2                           arm64        Python 3 bindings for TensorRT</span><br><span class="hljs-string">ii  python3-libnvinfer-dev                                8.2.1-1+cuda10.2                           arm64        Python 3 development package for TensorRT</span><br><span class="hljs-string">ii  tensorrt                                              8.2.1.9-1+cuda10.2                         arm64        Meta package of TensorRT</span><br><span class="hljs-string">ii  uff-converter-tf                                      8.2.1-1+cuda10.2                           arm64        UFF converter for TensorRT package</span><br><span class="hljs-string"></span><br><span class="hljs-string"># 系统版本</span><br><span class="hljs-string">(mmdeploy36) npu@ubuntu:~$ cat /etc/lsb-release</span><br><span class="hljs-string">DISTRIB_ID=Ubuntu</span><br><span class="hljs-string">DISTRIB_RELEASE=18.04</span><br><span class="hljs-string">DISTRIB_CODENAME=bionic</span><br><span class="hljs-string">DISTRIB_DESCRIPTION=&quot;Ubuntu 18.04.6 LTS&quot;</span><br><span class="hljs-string"></span><br><span class="hljs-string"># 系统内核</span><br><span class="hljs-string">(mmdeploy36) npu@ubuntu:~$ uname -a</span><br><span class="hljs-string">Linux ubuntu 4.9.337-tegra #1 SMP PREEMPT Thu Jun 8 21:09:35 PDT 2023 aarch64 aarch64 aarch64 GNU/Linux</span><br><span class="hljs-string"></span><br><span class="hljs-string"># 内存</span><br><span class="hljs-string">(mmdeploy36) npu@ubuntu:~$ free -m</span><br><span class="hljs-string">              total        used        free      shared  buff/cache   available</span><br><span class="hljs-string">Mem:           7858        3042         766         277        4049        4465</span><br><span class="hljs-string">Swap:          3929           0        3928</span><br><span class="hljs-string"></span><br><span class="hljs-string"># CPU</span><br><span class="hljs-string">(mmdeploy36) npu@ubuntu:~$ lscpu</span><br><span class="hljs-string">Architecture:         aarch64</span><br><span class="hljs-string">Byte Order:           Little Endian</span><br><span class="hljs-string">CPU(s):               6</span><br><span class="hljs-string">On-line CPU(s) list:  0,3-5</span><br><span class="hljs-string">Off-line CPU(s) list: 1,2</span><br><span class="hljs-string">Thread(s) per core:   1</span><br><span class="hljs-string">Core(s) per socket:   4</span><br><span class="hljs-string">Socket(s):            1</span><br><span class="hljs-string">Vendor ID:            ARM</span><br><span class="hljs-string">Model:                3</span><br><span class="hljs-string">Model name:           Cortex-A57</span><br><span class="hljs-string">Stepping:             r1p3</span><br><span class="hljs-string">CPU max MHz:          2035.2000</span><br><span class="hljs-string">CPU min MHz:          345.6000</span><br><span class="hljs-string">BogoMIPS:             62.50</span><br><span class="hljs-string">L1d cache:            32K</span><br><span class="hljs-string">L1i cache:            48K</span><br><span class="hljs-string">L2 cache:             2048K</span><br><span class="hljs-string">Flags:                fp asimd evtstrm aes pmull sha1 sha2 crc32</span><br><span class="hljs-string"></span><br><span class="hljs-string"># 硬盘</span><br><span class="hljs-string">(mmdeploy36) npu@ubuntu:~$ df -h</span><br><span class="hljs-string">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="hljs-string">/dev/mmcblk0p1   28G   16G   11G  59% /</span><br><span class="hljs-string">none            3.5G     0  3.5G   0% /dev</span><br><span class="hljs-string">tmpfs           3.9G  162M  3.7G   5% /dev/shm</span><br><span class="hljs-string">tmpfs           3.9G   96M  3.8G   3% /run</span><br><span class="hljs-string">tmpfs           5.0M  4.0K  5.0M   1% /run/lock</span><br><span class="hljs-string">tmpfs           3.9G     0  3.9G   0% /sys/fs/cgroup</span><br><span class="hljs-string">tmpfs           786M  136K  786M   1% /run/user/1000</span><br><span class="hljs-string">/dev/loop0       16M  130K   16M   1% /media/npu/L4T-README</span><br><span class="hljs-string"></span><br><span class="hljs-string"># nvcc</span><br><span class="hljs-string">(mmdeploy36) npu@ubuntu:~$ nvcc -V</span><br><span class="hljs-string">nvcc: NVIDIA (R) Cuda compiler driver</span><br><span class="hljs-string">Copyright (c) 2005-2021 NVIDIA Corporation</span><br><span class="hljs-string">Built on Sun_Feb_28_22:34:44_PST_2021</span><br><span class="hljs-string">Cuda compilation tools, release 10.2, V10.2.300</span><br><span class="hljs-string">Build cuda_10.2_r440.TC440_70.29663091_0</span><br><span class="hljs-string"></span><br><span class="hljs-string"># cuda</span><br><span class="hljs-string">(mmdeploy36) npu@ubuntu:~$ cat /usr/local/cuda/version.txt</span><br><span class="hljs-string">CUDA Version 10.2.300</span><br></code></pre></td></tr></table></figure>

<h1 id="Set-Git"><a href="#Set-Git" class="headerlink" title="Set Git"></a>Set Git</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs bash">(mmdeploy36) npu@ubuntu:~/MyDownload$ git config --global user.name murphyhoucn<br>(mmdeploy36) npu@ubuntu:~/MyDownload$ git config --global user.email cosmicdustycn@outlook.com<br>(mmdeploy36) npu@ubuntu:~/MyDownload$ git config user.name<br>murphyhoucn<br>(mmdeploy36) npu@ubuntu:~/MyDownload$ git config user.email<br>cosmicdustycn@outlook.com<br>(mmdeploy36) npu@ubuntu:~/MyDownload$ git config --global  --list<br>user.name=murphyhoucn<br>user.email=cosmicdustycn@outlook.com<br><br>(mmdeploy36) npu@ubuntu:~/MyDownload$ ssh-keygen -t rsa -C <span class="hljs-string">&quot;cosmicdustycn@outlook.com&quot;</span><br>(mmdeploy36) npu@ubuntu:~/MyDownload$ ssh -T git@github.com<br>Hi murphyhoucn! You<span class="hljs-string">&#x27;ve successfully authenticated, but GitHub does not provide shell access.</span><br></code></pre></td></tr></table></figure>



<h1 id="ARM64-and-aarch64-的区别"><a href="#ARM64-and-aarch64-的区别" class="headerlink" title="ARM64 and aarch64 的区别"></a>ARM64 and aarch64 的区别</h1><blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_33121481/article/details/122602974">arm64和aarch64之间的区别_aarch和arm架构的区别-CSDN博客</a></p>
<p>直接给出结论：arm64已经与aarch64合并，因为aarch64和arm64指的是同一件事。</p>
</blockquote>
<p>AArch64是 ARMv8 架构的一种执行状态。<br>为了更广泛地向企业领域推进，需要引入 64 位构架。同时也需要在 ARMv8 架构中引入新的 AArch64 执行状态。AArch64 不是一个单纯的 32 位 ARM 构架扩展，而是 ARMv8 内全新的构架，完全使用全新的 A64 指令集。这些都源自于多年对现代构架设计的深入研究。更重要的是， AArch64 作为一个分离出的执行状态，意味着一些未来的处理器可能不支持旧的 AArch32 执行状态。 虽然最初的 64 位 ARM 处理器将会完全向后兼容，但我们大胆且前瞻性地将 AArch64 作为在 ARMv8 处理器中唯一的执行状态。我们在这些系统中将不支持 32 位执行状态， 这将使许多有益的实现得到权衡，如默认情况下，使用一个较大的 64K 大小的页面，并会使得纯净的 64 位 ARM 服务器系统不受遗留代码的影响。立即进行这种划分是很重要的，因为有可能在未来几年内将出现仅支持 64 位的服务器系统。没有必要在新的 64 位架构中去实现一个完整的 32 位流水线，这将会提高未来 ARM 服务器系统的能效。这样回想起来， AArch64 作为在 Fedora ARM 项目中被支持的 ARM 构架是一个很自然的过程： armv5tel、armv7hl、aarch64。新的架构被命名为：aarch64，这同 ARM 自己选择的主线命名方式保持一致，同时也考虑到了 ARM 架构名与 ARM 商标分开的期望。</p>
<p>ARM64是由Apple创建的，而AARCH64是由其他人（最著名的是GNU &#x2F; GCC的）创建的。<br>经过一番谷歌搜索后，我发现LLVM 64位ARM64 &#x2F; AArch64后端已合并，用于aarch64的Apple后端称为arm64，而LLVM 编译器社区开发的后端称为aarch64（因为它是64位ISA的规范名称），后来将arm64和 aarch64 两者合并，现在的后端称为aarch64。 。</p>
<h1 id="安装miniconda-不要安装"><a href="#安装miniconda-不要安装" class="headerlink" title="安装miniconda (不要安装)"></a>安装miniconda (不要安装)</h1><blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/656004165">https://zhuanlan.zhihu.com/p/656004165</a><br>踩坑：直接安装Miniconda3 aarch64的latest版本不行！</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://repo.anaconda.com/miniconda/Miniconda3-py37_4.9.2-Linux-aarch64.sh<br><span class="hljs-built_in">sudo</span> bash Miniconda3-py37_4.9.2-Linux-aarch64.sh<br></code></pre></td></tr></table></figure>
<p>之后一路ENTER, 空格，yes，等，安装成功后，会出现“Thank you”。</p>
<p>安装完成之后的conda不能直接用，刷新一下环境变量就好了。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">source</span> ~/.bashrc<br></code></pre></td></tr></table></figure>

<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051118383.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="image-20250604132727339"></p>
<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051118055.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="image-20250604132735391"></p>
<h1 id="拼音输入法"><a href="#拼音输入法" class="headerlink" title="拼音输入法"></a>拼音输入法</h1><blockquote>
<ul>
<li><a target="_blank" rel="noopener" href="https://juejin.cn/post/7022845968219389959">https://juejin.cn/post/7022845968219389959</a></li>
</ul>
</blockquote>
<p>教程有效！</p>
<p>输入法切换快捷键：ctrl+space</p>
<h1 id="Windows-host连接-TX2"><a href="#Windows-host连接-TX2" class="headerlink" title="Windows host连接 TX2"></a>Windows host连接 TX2</h1><blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/zhang_zeng/article/details/77945317">Jetson TX2使用系列（2）-远程连接TX2_jestontx2 ssh-CSDN博客</a></p>
</blockquote>
<p>Linux: ifconfig</p>
<p>Winodw: ipconfig</p>
<p>两个设备连接的是同一个WiFi路由器。但仍然有可能不是同一个子网。第一次就遇到了这个情况，（计算机网络的知识都忘记得差不多了），直接把TX2断了WiFi，重新连接了一下，然后就跟host在同一个子网了。两个ip可以ping通。</p>
<div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051118456.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="image-20250604131658954"></div><div class="group-image-wrap"><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051118345.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="可以直接使用ssh连接到TX2，不用两套键鼠切换了！"></div><div class="group-image-wrap"><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051118858.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="FileZilla也可以连接，不用再借飞书传文件了！"></div></div></div>


<h1 id="设置TX2不休眠"><a href="#设置TX2不休眠" class="headerlink" title="设置TX2不休眠"></a>设置TX2不休眠</h1><blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/ZHOUYONGXYZ/article/details/111947659">Jetson TX2 Nano NX 系列设备设置不休眠_tx2 nx怎么设置待机时间-CSDN博客</a></p>
</blockquote>
<p>有效！</p>
<h1 id="代理-SS-SSR"><a href="#代理-SS-SSR" class="headerlink" title="代理 SS&#x2F;SSR"></a>代理 SS&#x2F;SSR</h1><blockquote>
<ul>
<li><a target="_blank" rel="noopener" href="https://githubwyb.github.io/blogs/2021-03-05-shadowsocks/">linux下shadowsocks代理配置（服务端+客户端） | 技术的路上奔跑</a></li>
<li><a target="_blank" rel="noopener" href="https://www.linuxssr.com/kb/what-is-ssr/">SSR是什么? - SSR中文网</a></li>
</ul>
</blockquote>
<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051119839.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="image-20250604140344374"></p>
<h1 id="Clash-for-Linux"><a href="#Clash-for-Linux" class="headerlink" title="Clash for Linux"></a>Clash for Linux</h1><blockquote>
<p><a target="_blank" rel="noopener" href="https://github.com/wnlen/clash-for-linux#">wnlen&#x2F;clash-for-linux: clash-for-linux</a></p>
</blockquote>
<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051119253.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="wget可以访问Google。但是直接使用浏览器，Google还是不行！"></p>
<h1 id="MMdeploy-安装"><a href="#MMdeploy-安装" class="headerlink" title="MMdeploy 安装"></a>MMdeploy 安装</h1><blockquote>
<p><a target="_blank" rel="noopener" href="https://mmdeploy.readthedocs.io/zh-cn/v1.3.1/01-how-to-build/jetsons.html">如何在 Jetson 模组上安装 MMDeploy — mmdeploy 1.3.1 文档</a></p>
</blockquote>
<h2 id="conda"><a href="#conda" class="headerlink" title="conda"></a>conda</h2><p>mmdeploy文档说，安装Conda需要使用Archiconda！</p>
<div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051119834.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="image-20250604132814269"></div><div class="group-image-wrap"><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051119220.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="之前的miniconda的环境变量就注释了"></div></div></div>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 得到默认安装的 python3 版本</span><br><span class="hljs-built_in">export</span> PYTHON_VERSION=`python3 --version | <span class="hljs-built_in">cut</span> -d<span class="hljs-string">&#x27; &#x27;</span> -f 2 | <span class="hljs-built_in">cut</span> -d<span class="hljs-string">&#x27;.&#x27;</span> -f1,2`<br>conda create -y -n mmdeploy python=<span class="hljs-variable">$&#123;PYTHON_VERSION&#125;</span><br>conda activate mmdeploy<br></code></pre></td></tr></table></figure>

<p>这样安装的python版本是3.7的，看<a target="_blank" rel="noopener" href="https://forums.developer.nvidia.com/t/pytorch-for-jetson-version-1-10-now-available/72048">nvidia pytorch for jetson </a>这里只提供了py36的包，mmdeploy也说了是py36，所以又手动创建了一个mmdeploy36的环境。后面知道是什么原因了，在创建环境的时候处在了base环境下，这时候的python版本的base的，不是TX2自带的。后面手动创建的36应该问题也不大！</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 系统自带的python版本</span><br>npu@ubuntu:~$ python --version<br>Python 2.7.17<br>npu@ubuntu:~$ python3 --version<br>Python 3.6.9<br><br><span class="hljs-comment"># conda安装的python版本</span><br>npu@ubuntu:~$ conda <span class="hljs-built_in">env</span> list<br><span class="hljs-comment"># conda environments:</span><br><span class="hljs-comment">#</span><br>base                  *  /home/npu/archiconda3<br>mmdeploy                 /home/npu/archiconda3/envs/mmdeploy<br>mmdeploy36               /home/npu/archiconda3/envs/mmdeploy36<br>                         /home/npu/miniconda3<br><br>npu@ubuntu:~$ conda activate base<br>(base) npu@ubuntu:~$ python3 --version<br>Python 3.7.1<br>(base) npu@ubuntu:~$ conda activate mmdeploy<br>(mmdeploy) npu@ubuntu:~$ python3 --version<br>Python 3.7.2<br>(mmdeploy) npu@ubuntu:~$ conda activate mmdeploy36<br>(mmdeploy36) npu@ubuntu:~$ python3 --version<br>Python 3.6.15<br></code></pre></td></tr></table></figure>



<h2 id="PyTorch"><a href="#PyTorch" class="headerlink" title="PyTorch"></a>PyTorch</h2><ul>
<li>torch按照教程。但是nvidia的网站访问首先，只能从host下载，然后传过去，再进行安装。</li>
<li>vision从github clone不下来。在host clone然后再传过去。（项目repo太大了，要clone很久。</li>
</ul>
<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051119819.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="image-20250604133407761"></p>
<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051119295.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="运行了超级久！"></p>
<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051119172.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="image-20250604155532574"></p>
<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051119973.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="验证一下"></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/632183060">在Jetson上部署mmdeploy的流程及采坑心得 - 知乎</a></p>
</blockquote>
<h2 id="cmake"><a href="#cmake" class="headerlink" title="cmake"></a>cmake</h2><p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051119581.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="image-20250604150624867"></p>
<h2 id="mmcv"><a href="#mmcv" class="headerlink" title="mmcv"></a>mmcv</h2><p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051119978.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="mmcv 要求python &gt; 3.7!"></p>
<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051119371.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="2.x 不支持python 3.6"></p>
<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051119579.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="mmcv文档中说支持的！[从源码编译 MMCV — mmcv 1.4.1 文档](https://mmcv.readthedocs.io/zh-cn/v1.4.1/get_started/build.html)"></p>
<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051340984.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="不支持&lt;3.7!  [Releases · open-mmlab/mmcv](https://github.com/open-mmlab/mmcv/releases)"></p>
<blockquote>
<p>吐槽：OpenMMLab的这些开源库做的确实很好，但是版本控制搞得太差了！代码的可读性也很差！每次装都出现大量的问题，搞崩溃了！</p>
</blockquote>
<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051119641.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="试一下强制让2.x支持3.6？不行！还是一样的错误，可能判断逻辑不在这里"></p>
<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051119507.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="没办法了，只能试一下1.x版本行不行了"></p>
<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051119198.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="终于安装好了！安装了一下午+一晚上！"></p>
<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051119843.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="image-20250604204026207"></p>
<h2 id="h5py-and-pycuda"><a href="#h5py-and-pycuda" class="headerlink" title="h5py and pycuda"></a>h5py and pycuda</h2><p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051120332.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="这两个安装都有问题"></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_42062018/article/details/119546939">Linux使用pip安装h5py失败解决办法_failed to build h5py-CSDN博客</a></p>
<p><a target="_blank" rel="noopener" href="https://pypi.org/project/pyopencl/2021.2.6/">pyopencl · PyPI</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/jetson-nano-wheels/python3.6-pycuda-2021.1">jetson-nano-wheels&#x2F;python3.6-pycuda-2021.1</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash">✅pip install <span class="hljs-string">&#x27;https://github.com/jetson-nano-wheels/python3.6-numpy-1.19.4/releases/download/v0.0.1/numpy-1.19.4-cp36-cp36m-linux_aarch64.whl&#x27;</span><br><br>pip install <span class="hljs-string">&#x27;https://github.com/jetson-nano-wheels/python3.6-pyopencl-2021.2.6/releases/download/v0.0.1/pyopencl-2021.2.6-cp36-cp36m-linux_aarch64.whl&#x27;</span><br><br>✅pip install <span class="hljs-string">&#x27;https://github.com/jetson-nano-wheels/python3.6-pycuda-2021.1/releases/download/v0.0.1/pycuda-2021.1-cp36-cp36m-linux_aarch64.whl&#x27;</span><br><br><span class="hljs-comment">## github直连不了就行下载到本地，然后传到TX2</span><br><span class="hljs-comment">## 第二个的离线包都下载不了？？</span><br><br><span class="hljs-comment"># 直接把这个repo clone下来，按照readme，执行init.sh就行</span><br></code></pre></td></tr></table></figure>
<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051120785.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="好像还是没有opencl"></p>
<h2 id="Model-Converter"><a href="#Model-Converter" class="headerlink" title="Model Converter"></a>Model Converter</h2><p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051120661.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="这里报错，过不去了！"></p>
<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051120482.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="少了cuda的库？？"></p>
<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051120007.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="image-20250605103102934"></p>
<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051120011.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="image-20250605103112840"></p>
<p>找到问题了！</p>
<p>文档中使用的clone命令是</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> --recursive https://github.com/open-mmlab/mmdeploy.git<br><span class="hljs-comment"># 递归把第三方库的指定commit版本下载下来。</span><br><span class="hljs-comment"># 但是网络问题，这几个第三方库都clone不下来</span><br><span class="hljs-comment"># 我只能手动clone.</span><br><span class="hljs-comment"># 但是手动clone的是main分支的最新版本。需要手动再回退到指定的commit中！</span><br></code></pre></td></tr></table></figure>

<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051120620.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="回退到指定commit"></p>
<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051120731.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="回退到指定commit"></p>
<blockquote>
<ul>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/zhangge3663/article/details/115335241">git clone 获取指定分支的指定commit版本_git clone 指定commit-CSDN博客</a></li>
</ul>
</blockquote>
<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051349345.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="image-20250605134932691"></p>
<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051343598.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="？怎么ONNX版本跟之前说得不一样了？"></p>
<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051343351.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="版本冲突！为什么要装更高的onnx呢？"></p>
<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051343713.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="这个版本应该可以吧！"></p>
<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051343377.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="不要这个看看！"></p>
<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051343163.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="虽然报了好多好多错！但最后应该是是可以了吧？"></p>
<p><img src="/./InitJetsonTX2.assets/image-20250605140610891.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="image-20250605140610891"></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install mmdet<br></code></pre></td></tr></table></figure>



<h1 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h1><h2 id="如何转换模型"><a href="#如何转换模型" class="headerlink" title="如何转换模型"></a>如何转换模型</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">python ./tools/deploy.py \<br>    configs/mmdet/detection/detection_tensorrt_dynamic-320x320-1344x1344.py \<br>    /home/npu/MyDownload/mmdetection/configs/yolo/yolov3_d53_8xb8-ms-608-273e_coco.py \<br>	/home/npu/MyDownload/mmdetection/checkpoints/yolo/yolov3_d53_mstrain-608_273e_coco_20210518_115020-a2c3acb8.pth \<br>    /home/npu/MyDownload/mmdetection/demo/demo.jpg \<br>    --work-dir work_dir \<br>    --device cuda:0 \<br></code></pre></td></tr></table></figure>

<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506061105821.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="mmcv版本不行！"></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> mmdeploy<br><br><span class="hljs-comment"># download faster r-cnn model from mmdet model zoo</span><br>mim download mmdet --config faster-rcnn_r50_fpn_1x_coco --dest .<br><br><span class="hljs-comment"># convert mmdet model to onnxruntime model with dynamic shape</span><br>python tools/deploy.py \<br>    configs/mmdet/detection/detection_onnxruntime_dynamic.py \<br>    faster-rcnn_r50_fpn_1x_coco.py \<br>    faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth \<br>    demo/resources/det.jpg \<br>    --work-dir mmdeploy_models/mmdet/ort \<br>    --device cuda \<br>    --show \<br>    --dump-info<br></code></pre></td></tr></table></figure>

<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506061105822.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="image-20250605141711215"></p>
<p>结果：最后在这个TX2上安装mmdeploy环境失败了！</p>
<h1 id="思考一下"><a href="#思考一下" class="headerlink" title="思考一下"></a>思考一下</h1><p>MMdeploy是用于把深度学习模型进行部署的工具。</p>
<p>但我现在想做的工作应该是MMdeploy直接在服务器上部署，然后转换的模型部署在TX2上运行。</p>
<blockquote>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmdeploy/blob/main/docs/zh_cn/get_started.md">https://github.com/open-mmlab/mmdeploy/blob/main/docs/zh_cn/get_started.md</a></li>
<li>按照文档配了环境，然后转换了一个ONNX模型。</li>
</ul>
</blockquote>
<h1 id="Deploy-tutorial"><a href="#Deploy-tutorial" class="headerlink" title="Deploy tutorial"></a>Deploy tutorial</h1><blockquote>
<p><a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmdeploy/tree/master/docs/zh_cn/tutorial">mmdeploy&#x2F;docs&#x2F;zh_cn&#x2F;tutorial at master · open-mmlab&#x2F;mmdeploy</a></p>
</blockquote>
<ul>
<li>PyTorch 模型部署到推理引擎  ONNX Runtime&#x2F;TensorRT 上</li>
<li>部署流水线 PyTorch - ONNX - ONNX Runtime&#x2F;TensorRT</li>
</ul>
<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506051617483.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="流水线"></p>
<p>以下是对这些技术和框架的详细解释：</p>
<ol>
<li><strong>PyTorch（Meta）</strong>：PyTorch是由Meta（原Facebook）开发的开源深度学习框架。它以动态计算图、自动求导、Pythonic设计等特性简化了开发流程，提供了模块化神经网络构建和标准化训练流程组件，广泛应用于计算机视觉、自然语言处理、生成式模型等多个领域。其核心设计理念是“灵活性优先”，支持开发者快速迭代实验模型，同时兼顾高效计算与生产部署需求。截至当前，全球超过70%的顶尖AI研究论文使用PyTorch实现。</li>
<li>TensorFlow&#x2F;Caffe（Google）：<ul>
<li><strong>TensorFlow</strong>：是由Google开发和维护的开源机器学习框架，自2015年发布以来，在学术界和工业界广泛应用。它支持在CPU、GPU、TPU等多种硬件设备上运行，可用于图像识别、自然语言处理、语音识别、推荐系统等多种机器学习和深度学习任务。TensorFlow支持多种编程语言，提供高层API（如Keras）和用于生产环境部署的工具套件（如TensorFlow Extended），具有灵活性、性能优化和多平台部署支持等优势。</li>
<li><strong>Caffe</strong>：由加州大学伯克利分校的伯克利人工智能研究实验室开发，是一个清晰、高效的深度学习框架，专注于速度、模块化和表达性，在图像分类和图像识别等领域有广泛应用，尤其在学术研究中曾被广泛使用。</li>
</ul>
</li>
<li><strong>MXNet（Amazon）</strong>：MXNet是亚马逊选择的深度学习库，它拥有类似于Theano和TensorFlow的数据流图，为多GPU配置提供了良好的支持，有类似于Lasagne和Blocks更高级别的模型构建块，并且可以在多种硬件上运行，包括手机。它支持多种编程语言，如Python、C++、R、Scala、Julia和Javascript等，具有强大的可扩展性，可在多场景下进行分布式计算，支持“先定义再计算”的延迟计算模式。</li>
<li><strong>ONNX（Open Neural Network Exchange）</strong> ：是一种开放的模型交换格式，由Facebook和微软在2017年共同发布，用于标准描述计算图。它允许不同的深度学习框架（如TensorFlow、PyTorch等）之间共享和转换模型，有助于消除不同深度学习框架之间的壁垒，促进模型共享和重用，使开发者可以更容易地与其他人合作，共享和部署他们的模型。</li>
<li><strong>ONNX Runtime</strong> ：是由微软维护的一个跨平台机器学习推理加速器，即“推理引擎”。它基于ONNX格式，提供了一套高性能库，用于在C等环境中高效执行这些ONNX格式的模型。其主要特点包括高性能、跨平台支持、可扩展性、内存管理和性能提升以及动态形状支持等，适用于云端服务、边缘设备、移动应用等多种人工智能应用场景。</li>
<li><strong>PPL（Parallel Patterns Library）</strong> ：即并行模式库，是Microsoft开发的用于简化并行编程的库，它提供了一组用于实现常见并行模式的模板和工具，可帮助开发者更轻松地编写并行代码，提高程序在多核处理器上的性能。</li>
<li><strong>ncnn（<a target="_blank" rel="noopener" href="https://github.com/Tencent/ncnn">Tencent&#x2F;ncnn: ncnn is a high-performance neural network inference framework optimized for the mobile platform</a>）</strong> ：ncnn是一个为手机端极致优化的高性能神经网络前向计算框架，由腾讯优图实验室开源。它针对移动端设备进行了深度优化，具有轻量级、高效率的特点，能够在不依赖第三方计算库的情况下，在移动设备上实现快速的卷积神经网络推理，广泛应用于移动端图像识别、目标检测等领域。需要注意的是，它并非由NVIDIA开发，与NVIDIA没有直接关联 。</li>
<li><strong>OpenVINO</strong> ：是英特尔开发的跨平台深度学习工具包，名称代表“开放式视觉推理和神经网络优化”。它能够优化深度学习模型的推理性能，支持多种硬件平台，包括英特尔的CPU、GPU、VPU等，可广泛应用于计算机视觉、语音识别、自然语言处理等领域，帮助开发者将深度学习模型部署到各种设备上，实现高效的推理和决策。</li>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/jit.html">TorchScript</a> 是一种序列化和优化 PyTorch 模型的格式，在优化过程中，一个<code>torch.nn.Module</code>模型会被转换成 TorchScript 的<code>torch.jit.ScriptModule</code>模型。现在， TorchScript 也被常当成一种中间表示使用。<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/486914187">TorchScript 解读（一）：初识 TorchScript - 知乎</a></li>
</ol>
<p><img src="/./InitJetsonTX2.assets/image-20250605163726818.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="vscode server上运行netron，host上直接访问对应端口的localhost可以直接可视化onnx模型"></p>
<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506061217094.png" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="img"></p>
<p><strong>ONNX 算子文档:</strong> ONNX 算子的定义情况，都可以在官方的<a target="_blank" rel="noopener" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md">算子文档</a>中查看。这份文档十分重要，我们碰到任何和 ONNX 算子有关的问题都得来”请教“这份文档。</p>
<p><strong>PyTorch 对 ONNX 算子的映射:</strong> 在 PyTorch 中，和 ONNX 有关的定义全部放在 <a target="_blank" rel="noopener" href="https://github.com/pytorch/pytorch/tree/master/torch/onnx">torch.onnx 目录</a>中</p>
<p>在实际的部署过程中，难免碰到模型无法用原生 PyTorch 算子表示的情况。这个时候，我们就得考虑扩充 PyTorch，即在 PyTorch 中支持更多 ONNX 算子。</p>
<p>而要使 PyTorch 算子顺利转换到 ONNX ，我们需要保证以下三个环节都不出错：</p>
<ul>
<li>算子在 PyTorch 中有实现</li>
<li>有把该 PyTorch 算子映射成一个或多个 ONNX 算子的方法</li>
<li>ONNX 有相应的算子</li>
</ul>
<p>可在实际部署中，这三部分的内容都可能有所缺失。其中最坏的情况是：我们定义了一个全新的算子，它不仅缺少 PyTorch 实现，还缺少 PyTorch 到 ONNX 的映射关系。但所谓车到山前必有路，对于这三个环节，我们也分别都有以下的添加支持的方法：</p>
<ul>
<li>PyTorch 算子<ul>
<li>组合现有算子</li>
<li>添加 TorchScript 算子</li>
<li>添加普通 C++ 拓展算子</li>
</ul>
</li>
<li>映射方法<ul>
<li>为 ATen 算子添加符号函数（<a target="_blank" rel="noopener" href="https://pytorch.org/cppdocs/#aten">ATen</a> 是 PyTorch 内置的 C++ 张量计算库，PyTorch 算子在底层绝大多数计算都是用 ATen 实现的。）</li>
<li>为 TorchScript 算子添加符号函数</li>
<li>封装成 torch.autograd.Function 并添加符号函数</li>
</ul>
</li>
<li>ONNX 算子<ul>
<li>使用现有 ONNX 算子</li>
<li>定义新 ONNX 算子</li>
</ul>
</li>
</ul>
<p>符号函数，可以看成是 PyTorch 算子类的一个静态方法。在把 PyTorch 模型转换成 ONNX 模型时，各个 PyTorch 算子的符号函数会被依次调用，以完成 PyTorch 算子到 ONNX 算子的转换。</p>
<p>ONNX 在底层是用 <strong>Protobuf</strong> 定义的。Protobuf，全称 Protocol Buffer，是 Google 提出的一套表示和序列化数据的机制。使用 Protobuf 时，用户需要先写一份数据定义文件，再根据这份定义文件把数据存储进一份二进制文件。</p>
<p> ONNX 模型是按以下的结构组织起来的：</p>
<ul>
<li>ModelProto<ul>
<li>GraphProto<ul>
<li>NodeProto</li>
<li>ValueInfoProto</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="https://murphyimg.oss-cn-beijing.aliyuncs.com/img/202506061523969.jpeg" srcset="https://murhyimgur.oss-cn-beijing.aliyuncs.com/website/loading.gif" lazyload alt="ONNX 模型的结构可以用类图大致表示"></p>
<p>ONNX 提供了 API <code>onnx.checker.check_model</code> 来判断一个 ONNX 模型是否满足标准。</p>
<p>我们使用 TensorRT 生成模型主要有两种方式：</p>
<ol>
<li>直接通过 TensorRT 的 API 逐层搭建网络；</li>
<li>将中间表示的模型转换成 TensorRT 的模型，比如将 ONNX 模型转换成 TensorRT 模型。</li>
</ol>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/CV/" class="category-chain-item">CV</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/OpenMMLab/" class="print-no-link">#OpenMMLab</a>
      
        <a href="/tags/EdgeComputing/" class="print-no-link">#EdgeComputing</a>
      
        <a href="/tags/Arm/" class="print-no-link">#Arm</a>
      
        <a href="/tags/MMDeploy/" class="print-no-link">#MMDeploy</a>
      
        <a href="/tags/MMCV/" class="print-no-link">#MMCV</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>JetsonTX2</div>
      <div>https://blog.cosmicdusty.cc/post/CV/InitJetsonTX2/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Murphy</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2024年4月23日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/post/Knowledge/FixLinuxGrub/" title="FixLinuxGrub">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">FixLinuxGrub</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/post/MyLife/TripToNanJing2024/" title="南京之行2024">
                        <span class="hidden-mobile">南京之行2024</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <div id="valine"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#valine', function() {
      Fluid.utils.createScript('https://lib.baomitu.com/valine/1.5.1/Valine.min.js', function() {
        var options = Object.assign(
          {"appId":"JijHNKemeVNog4wF7g9I5TR3-gzGzoHsz","appKey":"FvsKdxHOP2aG5rHrHby5aV0b","path":"window.location.pathname","placeholder":null,"avatar":"retro","meta":["nick","mail","link"],"requiredFields":[],"pageSize":10,"lang":"zh-CN","highlight":false,"recordIP":false,"serverURLs":"","emojiCDN":null,"emojiMaps":null,"enableQQ":false},
          {
            el: "#valine",
            path: window.location.pathname
          }
        )
        new Valine(options);
        Fluid.utils.waitElementVisible('#valine .vcontent', () => {
          var imgSelector = '#valine .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a rel="nofollow noopener"><span>Powered by</span></a> <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span><b>Hexo</b></span></a> <i class="iconfont icon-love"></i> <a rel="nofollow noopener"><span>Themed by</span></a> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span><b>Fluid</b></span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量
        <span id="busuanzi_value_site_pv"></span>
        次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数
        <span id="busuanzi_value_site_uv"></span>
        人
      </span>
    
    

  

</div>

  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script defer src="/js/leancloud.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
